{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10418373,"sourceType":"datasetVersion","datasetId":6456991}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom textblob import TextBlob\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T07:59:28.662393Z","iopub.execute_input":"2025-01-10T07:59:28.663135Z","iopub.status.idle":"2025-01-10T07:59:28.669420Z","shell.execute_reply.started":"2025-01-10T07:59:28.663092Z","shell.execute_reply":"2025-01-10T07:59:28.668002Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Load the dataset","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/beer-rating-reviews/train.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T07:59:29.607725Z","iopub.execute_input":"2025-01-10T07:59:29.608106Z","iopub.status.idle":"2025-01-10T07:59:30.183084Z","shell.execute_reply.started":"2025-01-10T07:59:29.608076Z","shell.execute_reply":"2025-01-10T07:59:30.181781Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# Initial data cleaning","metadata":{}},{"cell_type":"code","source":"data['review/text'] = data['review/text'].fillna(\"No review provided\")\ndata['user/gender'] = data['user/gender'].fillna('Unknown')\ndata = data.drop(['user/ageInSeconds', 'user/birthdayRaw', 'user/birthdayUnix'], axis=1)\ndata = data.dropna(subset=['user/profileName'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T07:59:30.304747Z","iopub.execute_input":"2025-01-10T07:59:30.305145Z","iopub.status.idle":"2025-01-10T07:59:30.344889Z","shell.execute_reply.started":"2025-01-10T07:59:30.305112Z","shell.execute_reply":"2025-01-10T07:59:30.343826Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"def create_advanced_features(data):\n    features = data.copy()\n    \n    # 1. Rating-based Features\n    rating_cols = ['review/appearance', 'review/aroma', 'review/palate', 'review/taste']\n    features['rating_std'] = features[rating_cols].std(axis=1)\n    features['rating_range'] = features[rating_cols].max(axis=1) - features[rating_cols].min(axis=1)\n    \n    # Weighted Ratings\n    weights = {\n        'review/taste': 0.4,\n        'review/aroma': 0.3,\n        'review/palate': 0.2,\n        'review/appearance': 0.1\n    }\n    features['weighted_rating'] = sum(features[col] * weight for col, weight in weights.items())\n    \n    # Rating Ratios\n    features['taste_aroma_ratio'] = features['review/taste'] / features['review/aroma']\n    features['palate_appearance_ratio'] = features['review/palate'] / features['review/appearance']\n    \n    # 2. Style and ABV Features\n    style_means = features.groupby('beer/style')['review/overall'].mean()\n    features['style_avg_rating'] = features['beer/style'].map(style_means)\n    features['abv_category'] = pd.qcut(features['beer/ABV'], q=5, labels=['very_low', 'low', 'medium', 'high', 'very_high'])\n    features['abv_squared'] = features['beer/ABV'] ** 2\n    \n    # 3. Time Features\n    features['review_hour'] = pd.to_datetime(features['review/timeUnix'], unit='s').dt.hour\n    features['review_day'] = pd.to_datetime(features['review/timeUnix'], unit='s').dt.dayofweek\n    features['is_weekend'] = features['review_day'].isin([5, 6]).astype(int)\n    \n    # 4. Text Features\n    features['text_length'] = features['review/text'].str.len()\n    features['word_count'] = features['review/text'].str.split().str.len()\n    \n    # Sentiment Analysis\n    def get_sentiment(text):\n        return TextBlob(str(text)).sentiment.polarity\n    features['review_sentiment'] = features['review/text'].apply(get_sentiment)\n    \n    # Keyword Features\n    positive_keywords = ['excellent', 'amazing', 'perfect', 'fantastic', 'great']\n    negative_keywords = ['poor', 'bad', 'disappointing', 'awful', 'mediocre']\n    \n    def count_keywords(text, keyword_list):\n        return sum(word.lower() in str(text).lower() for word in keyword_list)\n    \n    features['positive_keyword_count'] = features['review/text'].apply(lambda x: count_keywords(x, positive_keywords))\n    features['negative_keyword_count'] = features['review/text'].apply(lambda x: count_keywords(x, negative_keywords))\n    \n    # 5. User Features\n    user_review_counts = features.groupby('user/profileName').size()\n    user_avg_ratings = features.groupby('user/profileName')['review/overall'].mean()\n    \n    features['user_review_count'] = features['user/profileName'].map(user_review_counts)\n    features['user_avg_rating'] = features['user/profileName'].map(user_avg_ratings)\n    features['user_experience'] = pd.qcut(features['user_review_count'], q=5, labels=['novice', 'casual', 'regular', 'experienced', 'expert'])\n    \n    # 6. Brewery Features\n    brewery_reviews = features.groupby('beer/brewerId').size()\n    brewery_avg_ratings = features.groupby('beer/brewerId')['review/overall'].mean()\n    \n    features['brewery_review_count'] = features['beer/brewerId'].map(brewery_reviews)\n    features['brewery_avg_rating'] = features['beer/brewerId'].map(brewery_avg_ratings)\n    \n    return features\n\n# Create features\nprint(\"Creating features...\")\nfeatures = create_advanced_features(data)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T07:59:31.067119Z","iopub.execute_input":"2025-01-10T07:59:31.067494Z","iopub.status.idle":"2025-01-10T08:00:11.245385Z","shell.execute_reply.started":"2025-01-10T07:59:31.067461Z","shell.execute_reply":"2025-01-10T08:00:11.244109Z"}},"outputs":[{"name":"stdout","text":"Creating features...\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# Prepare for modeling","metadata":{}},{"cell_type":"code","source":"print(\"Preparing for modeling...\")\n# Convert categorical variables\nle = LabelEncoder()\ncategorical_cols = ['abv_category', 'user_experience', 'beer/style']\nfor col in categorical_cols:\n    features[col] = le.fit_transform(features[col])\n\n# Select features\nselected_features = [\n    'weighted_rating', 'style_avg_rating', 'beer/ABV', 'abv_squared',\n    'text_length', 'word_count', 'review_sentiment',\n    'user_review_count', 'user_avg_rating', 'brewery_avg_rating',\n    'positive_keyword_count', 'negative_keyword_count',\n    'rating_std', 'brewery_review_count', 'is_weekend',\n    'abv_category', 'user_experience', 'beer/style',\n    'review/taste', 'review/aroma', 'review/appearance', 'review/palate'\n]\n\nX = features[selected_features]\ny = features['review/overall']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T08:00:11.246945Z","iopub.execute_input":"2025-01-10T08:00:11.247833Z","iopub.status.idle":"2025-01-10T08:00:11.288787Z","shell.execute_reply.started":"2025-01-10T08:00:11.247765Z","shell.execute_reply":"2025-01-10T08:00:11.287742Z"}},"outputs":[{"name":"stdout","text":"Preparing for modeling...\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# Train-test split & Scale features","metadata":{}},{"cell_type":"code","source":"print(\"Splitting data...\")\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint(\"Scaling features...\")\nscaler = StandardScaler()\nnumerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\nX_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\nX_test[numerical_cols] = scaler.transform(X_test[numerical_cols])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T08:00:11.291134Z","iopub.execute_input":"2025-01-10T08:00:11.291494Z","iopub.status.idle":"2025-01-10T08:00:11.349851Z","shell.execute_reply.started":"2025-01-10T08:00:11.291463Z","shell.execute_reply":"2025-01-10T08:00:11.348846Z"}},"outputs":[{"name":"stdout","text":"Splitting data...\nScaling features...\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# LightGBM & Xgboost Training","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nimport lightgbm as lgb\nimport xgboost as xgb\n\n# Train LightGBM Model\nprint(\"\\nTraining LightGBM model...\")\nlgb_model = lgb.LGBMRegressor(\n    n_estimators=200,\n    learning_rate=0.1,\n    max_depth=-1,\n    random_state=42\n)\nlgb_model.fit(X_train, y_train)\n\n# Perform Cross-Validation for LightGBM\nprint(\"\\nPerforming cross-validation for LightGBM...\")\nlgb_cv_scores = cross_val_score(lgb_model, X, y, cv=5, scoring='r2')\nprint(f\"Cross-validation R2 scores (LightGBM): {lgb_cv_scores}\")\nprint(f\"Mean CV R2 (LightGBM): {lgb_cv_scores.mean():.4f} (+/- {lgb_cv_scores.std() * 2:.4f})\")\n\n# Train XGBoost Model\nprint(\"\\nTraining XGBoost model...\")\nxgb_model = xgb.XGBRegressor(\n    n_estimators=200,\n    learning_rate=0.1,\n    max_depth=6,\n    objective='reg:squarederror',\n    random_state=42\n)\nxgb_model.fit(X_train, y_train)\n\n# Perform Cross-Validation for XGBoost\nprint(\"\\nPerforming cross-validation for XGBoost...\")\nxgb_cv_scores = cross_val_score(xgb_model, X, y, cv=5, scoring='r2')\nprint(f\"Cross-validation R2 scores (XGBoost): {xgb_cv_scores}\")\nprint(f\"Mean CV R2 (XGBoost): {xgb_cv_scores.mean():.4f} (+/- {xgb_cv_scores.std() * 2:.4f})\")\n\n# Model Evaluation Function\ndef evaluate_model(model, model_name):\n    print(f\"\\nEvaluating {model_name}...\")\n    train_pred = model.predict(X_train)\n    test_pred = model.predict(X_test)\n    \n    metrics = {\n        'Train R2': r2_score(y_train, train_pred),\n        'Test R2': r2_score(y_test, test_pred),\n        'Train RMSE': np.sqrt(mean_squared_error(y_train, train_pred)),\n        'Test RMSE': np.sqrt(mean_squared_error(y_test, test_pred)),\n        'Train MAE': mean_absolute_error(y_train, train_pred),\n        'Test MAE': mean_absolute_error(y_test, test_pred)\n    }\n    \n    print(f\"\\n{model_name} Performance Metrics:\")\n    for metric_name, value in metrics.items():\n        print(f\"{metric_name}: {value:.4f}\")\n    \n    return metrics\n\n# Evaluate both models\nlgb_metrics = evaluate_model(lgb_model, \"LightGBM\")\nxgb_metrics = evaluate_model(xgb_model, \"XGBoost\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T08:00:11.351266Z","iopub.execute_input":"2025-01-10T08:00:11.351668Z","iopub.status.idle":"2025-01-10T08:00:21.052873Z","shell.execute_reply.started":"2025-01-10T08:00:11.351612Z","shell.execute_reply":"2025-01-10T08:00:21.051965Z"}},"outputs":[{"name":"stdout","text":"\nTraining LightGBM model...\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002794 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1909\n[LightGBM] [Info] Number of data points in the train set: 29996, number of used features: 22\n[LightGBM] [Info] Start training from score 3.887202\n\nPerforming cross-validation for LightGBM...\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003197 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1890\n[LightGBM] [Info] Number of data points in the train set: 29996, number of used features: 22\n[LightGBM] [Info] Start training from score 3.889885\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005703 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1883\n[LightGBM] [Info] Number of data points in the train set: 29996, number of used features: 22\n[LightGBM] [Info] Start training from score 3.888318\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006761 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 1890\n[LightGBM] [Info] Number of data points in the train set: 29996, number of used features: 22\n[LightGBM] [Info] Start training from score 3.891085\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003216 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1884\n[LightGBM] [Info] Number of data points in the train set: 29996, number of used features: 22\n[LightGBM] [Info] Start training from score 3.889952\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002038 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 1889\n[LightGBM] [Info] Number of data points in the train set: 29996, number of used features: 22\n[LightGBM] [Info] Start training from score 3.887552\nCross-validation R2 scores (LightGBM): [0.73758635 0.75037102 0.73941536 0.73162696 0.729814  ]\nMean CV R2 (LightGBM): 0.7378 (+/- 0.0145)\n\nTraining XGBoost model...\n\nPerforming cross-validation for XGBoost...\nCross-validation R2 scores (XGBoost): [0.7367456  0.74937748 0.73913038 0.72953395 0.72957729]\nMean CV R2 (XGBoost): 0.7369 (+/- 0.0147)\n\nEvaluating LightGBM...\n\nLightGBM Performance Metrics:\nTrain R2: 0.7990\nTest R2: 0.7364\nTrain RMSE: 0.3146\nTest RMSE: 0.3570\nTrain MAE: 0.2370\nTest MAE: 0.2698\n\nEvaluating XGBoost...\n\nXGBoost Performance Metrics:\nTrain R2: 0.8105\nTest R2: 0.7385\nTrain RMSE: 0.3055\nTest RMSE: 0.3555\nTrain MAE: 0.2292\nTest MAE: 0.2678\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# Feature Importance for LightGBM & XGboost","metadata":{}},{"cell_type":"code","source":"lgb_importance = pd.DataFrame({\n    'feature': selected_features,\n    'importance': lgb_model.feature_importances_\n}).sort_values('importance', ascending=False)\n\nprint(\"\\nTop 10 Most Important Features (LightGBM):\")\nprint(lgb_importance.head(10))\n\nxgb_importance = pd.DataFrame({\n    'feature': selected_features,\n    'importance': xgb_model.feature_importances_\n}).sort_values('importance', ascending=False)\n\nprint(\"\\nTop 10 Most Important Features (XGBoost):\")\nprint(xgb_importance.head(10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T08:00:21.053568Z","iopub.execute_input":"2025-01-10T08:00:21.054499Z","iopub.status.idle":"2025-01-10T08:00:21.073007Z","shell.execute_reply.started":"2025-01-10T08:00:21.054460Z","shell.execute_reply":"2025-01-10T08:00:21.071703Z"}},"outputs":[{"name":"stdout","text":"\nTop 10 Most Important Features (LightGBM):\n              feature  importance\n8     user_avg_rating         873\n7   user_review_count         623\n0     weighted_rating         540\n6    review_sentiment         531\n2            beer/ABV         452\n5          word_count         402\n4         text_length         395\n12         rating_std         312\n1    style_avg_rating         285\n17         beer/style         245\n\nTop 10 Most Important Features (XGBoost):\n                   feature  importance\n18            review/taste    0.683268\n0          weighted_rating    0.143844\n21           review/palate    0.043156\n8          user_avg_rating    0.025953\n2                 beer/ABV    0.013243\n7        user_review_count    0.012845\n10  positive_keyword_count    0.008100\n1         style_avg_rating    0.005877\n6         review_sentiment    0.005873\n17              beer/style    0.005821\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# Catboost Training","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostRegressor\n\n\n# Train CatBoost Model\nprint(\"\\nTraining CatBoost model...\")\ncatboost_model = CatBoostRegressor(\n    iterations=200,\n    learning_rate=0.1,\n    depth=6,\n    loss_function='RMSE',\n    random_seed=42,\n    verbose=False\n)\ncatboost_model.fit(X_train, y_train)\n\n# Perform Cross-Validation for CatBoost\nprint(\"\\nPerforming cross-validation for CatBoost...\")\ncatboost_cv_scores = cross_val_score(catboost_model, X, y, cv=5, scoring='r2')\nprint(f\"Cross-validation R2 scores (CatBoost): {catboost_cv_scores}\")\nprint(f\"Mean CV R2 (CatBoost): {catboost_cv_scores.mean():.4f} (+/- {catboost_cv_scores.std() * 2:.4f})\")\n\n# Evaluate CatBoost model using the existing evaluation function\ncatboost_metrics = evaluate_model(catboost_model, \"CatBoost\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T08:00:35.545822Z","iopub.execute_input":"2025-01-10T08:00:35.546374Z","iopub.status.idle":"2025-01-10T08:00:41.760147Z","shell.execute_reply.started":"2025-01-10T08:00:35.546320Z","shell.execute_reply":"2025-01-10T08:00:41.758846Z"}},"outputs":[{"name":"stdout","text":"\nTraining CatBoost model...\n\nPerforming cross-validation for CatBoost...\nCross-validation R2 scores (CatBoost): [0.73822085 0.75374321 0.74294789 0.73592595 0.73178606]\nMean CV R2 (CatBoost): 0.7405 (+/- 0.0151)\n\nEvaluating CatBoost...\n\nCatBoost Performance Metrics:\nTrain R2: 0.7584\nTest R2: 0.7410\nTrain RMSE: 0.3449\nTest RMSE: 0.3538\nTrain MAE: 0.2588\nTest MAE: 0.2676\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"# Feature importance for CatBoost","metadata":{}},{"cell_type":"code","source":"catboost_importance = pd.DataFrame({\n    'feature': selected_features,\n    'importance': catboost_model.feature_importances_\n}).sort_values('importance', ascending=False)\n\nprint(\"\\nTop 10 Most Important Features (CatBoost):\")\nprint(catboost_importance.head(10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T08:00:45.621316Z","iopub.execute_input":"2025-01-10T08:00:45.621677Z","iopub.status.idle":"2025-01-10T08:00:45.631689Z","shell.execute_reply.started":"2025-01-10T08:00:45.621645Z","shell.execute_reply":"2025-01-10T08:00:45.630377Z"}},"outputs":[{"name":"stdout","text":"\nTop 10 Most Important Features (CatBoost):\n              feature  importance\n18       review/taste   29.231018\n0     weighted_rating   25.792891\n8     user_avg_rating   17.188756\n21      review/palate    7.473979\n7   user_review_count    6.144437\n2            beer/ABV    2.189009\n6    review_sentiment    1.609152\n1    style_avg_rating    1.470656\n3         abv_squared    1.451591\n17         beer/style    1.256453\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"# Comparison of all three models","metadata":{}},{"cell_type":"code","source":"print(\"\\nModel Comparison Summary:\")\nmodels_comparison = pd.DataFrame({\n    'LightGBM': {\n        'Test R2': lgb_metrics['Test R2'],\n        'Test RMSE': lgb_metrics['Test RMSE'],\n        'Test MAE': lgb_metrics['Test MAE'],\n        'CV R2 Mean': lgb_cv_scores.mean()\n    },\n    'XGBoost': {\n        'Test R2': xgb_metrics['Test R2'],\n        'Test RMSE': xgb_metrics['Test RMSE'],\n        'Test MAE': xgb_metrics['Test MAE'],\n        'CV R2 Mean': xgb_cv_scores.mean()\n    },\n    'CatBoost': {\n        'Test R2': catboost_metrics['Test R2'],\n        'Test RMSE': catboost_metrics['Test RMSE'],\n        'Test MAE': catboost_metrics['Test MAE'],\n        'CV R2 Mean': catboost_cv_scores.mean()\n    }\n}).round(4)\n\nprint(models_comparison)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T08:00:47.591783Z","iopub.execute_input":"2025-01-10T08:00:47.592144Z","iopub.status.idle":"2025-01-10T08:00:47.602736Z","shell.execute_reply.started":"2025-01-10T08:00:47.592118Z","shell.execute_reply":"2025-01-10T08:00:47.601128Z"}},"outputs":[{"name":"stdout","text":"\nModel Comparison Summary:\n            LightGBM  XGBoost  CatBoost\nTest R2       0.7364   0.7385    0.7410\nTest RMSE     0.3570   0.3555    0.3538\nTest MAE      0.2698   0.2678    0.2676\nCV R2 Mean    0.7378   0.7369    0.7405\n","output_type":"stream"}],"execution_count":17}]}